{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff5e322a-5628-4fa0-b62c-bdacfe46633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "import importlib\n",
    "import inspect\n",
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "#\n",
    "from Pegasus.api import *\n",
    "\n",
    "# splinter\n",
    "import subprocess\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "splinter = importlib.import_module(\"splinter\")\n",
    "importlib.reload(splinter)\n",
    "\n",
    "import timeit\n",
    "import yaml as yaml\n",
    "import itertools\n",
    "import copy\n",
    "import logging\n",
    "import random\n",
    "from shutil import copyfile\n",
    "#logging.basicConfig(level=logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22ef6857-ab5a-4897-855f-7e42b9bad0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Returns true if running inside a jupyter notebook,\n",
    "# false when running as a simple python script\n",
    "# useful for handling command line options or\n",
    "# setting up notebook defaults\n",
    "# =================================================================\n",
    "def is_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "def save_notebook():\n",
    "    if is_notebook():\n",
    "        try:\n",
    "            # save this notebook as a raw python file as well please\n",
    "            get_ipython().system('jupyter nbconvert --to script CDO-workflow-slurm-splinter-workflow.ipynb')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df05f54f-894b-4d09-a6ea-d83369a82670",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_notebook:\n",
    "    print(sys.argv)\n",
    "    ARG_iterations = sys.argv[1]\n",
    "    ARG_forks      = sys.argv[2]\n",
    "    ARG_datasize   = sys.argv[3]\n",
    "    ARG_cdo        = sys.argv[4]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03320ac6-f48d-449e-b783-14e35bd73920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname is localhost, User is biddisco\n"
     ]
    }
   ],
   "source": [
    "hostname = os.getenv('HOSTNAME')\n",
    "user     = os.getenv('USER')\n",
    "if hostname is None:\n",
    "    hostname = 'localhost'\n",
    "if user is None:\n",
    "    user = 'biddisco'\n",
    "print(f'Hostname is {hostname}, User is {user}')\n",
    "\n",
    "# default parths for container\n",
    "BINARY_PATH  ='/home/scitech/shared-data/maestro-test/binaries/'\n",
    "MOCKTAGE_PATH='/home/scitech/mocktage/build/bin/'\n",
    "DATA_PATH    ='/home/scitech/shared-data/maestro-test/binaries/data/'\n",
    "SCRATCH_PATH ='/home/scitech/scratch/'\n",
    "BEEGFS_PATH  = ''\n",
    "\n",
    "if ('oryx' in hostname or 'localhost' in hostname):\n",
    "    BINARY_PATH  ='/home/biddisco/src/maestro/pegasus-workflow-development-environment/shared-data/maestro-test/binaries/'\n",
    "    MOCKTAGE_PATH='/home/biddisco/build/maestro/mocktage/bin/'\n",
    "    DATA_PATH    ='/home/biddisco/src/maestro/pegasus-workflow-development-environment/shared-data/maestro-test/binaries//data/'\n",
    "    SCRATCH_PATH ='/home/biddisco/temp/maestro/'\n",
    "    \n",
    "if ('daint' in hostname) or ('nid' in hostname):\n",
    "    BINARY_PATH  ='/scratch/snx3000/biddisco/shared-data/maestro-test/binaries/'\n",
    "    MOCKTAGE_PATH='/scratch/snx3000/biddisco/maestro/mocktage/bin/'\n",
    "    DATA_PATH    ='/scratch/snx3000/biddisco/shared-data/maestro-test/binaries/data/'\n",
    "    SCRATCH_PATH =os.getcwd()\n",
    "    BEEGFS_PATH  ='/users/' + user + '/beegfs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "478bd82a-73b0-46c8-9acd-fc07f338ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformation_catalog(wf):\n",
    "    \n",
    "    tc = TransformationCatalog()\n",
    "    trans = {}\n",
    "\n",
    "    exes = {}\n",
    "    binary_paths = [BINARY_PATH, MOCKTAGE_PATH]\n",
    "    \n",
    "    for base in binary_paths:\n",
    "        base_dir = os.path.dirname(base)\n",
    "\n",
    "        for fname in os.listdir(base_dir):\n",
    "            transformation = None\n",
    "            if fname[0] == '.':\n",
    "                continue\n",
    "            #print('Making transformation', os.path.join(base_dir, fname))\n",
    "            transformation = Transformation(fname, \n",
    "                                            site='local',\n",
    "                                            pfn=os.path.join(base_dir, fname), \n",
    "                                            is_stageable=False)\n",
    "            transformation.add_env(PATH=MOCKTAGE_PATH + ':' \n",
    "                                   + BINARY_PATH + ':' + '/usr/bin:/bin:.')\n",
    "\n",
    "            # memory requirement\n",
    "            transformation.add_profiles(Namespace.CONDOR, 'request_memory', '1 GB')\n",
    "\n",
    "            # some transformations can be clustered for effiency\n",
    "            #if fname in ['gmProject', 'mDiff', 'mDiffFit', 'mBackground']:\n",
    "            #    transformation.add_profiles(Namespace.PEGASUS, 'clusters.size', '3')\n",
    "\n",
    "            # keep a handle to added ones, for use later\n",
    "            trans[fname] = transformation\n",
    "\n",
    "            tc.add_transformations(transformation)\n",
    "\n",
    "    wf.add_transformation_catalog(tc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13706251-ba20-494e-8400-a1c5527c9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_site_catalog():\n",
    "    # create a SiteCatalog object\n",
    "    sc = SiteCatalog()\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # create a \"local\" site\n",
    "    local = Site(\"local\", arch=Arch.X86_64, os_type=OS.LINUX)\n",
    "\n",
    "    #pprint(dir(Directory))\n",
    "    # create and add a shared scratch and local storage directories to the site \"local\"\n",
    "    local_shared_scratch_dir = Directory(Directory.SHARED_SCRATCH, path=SCRATCH_PATH)\\\n",
    "        .add_file_servers(FileServer(\"file://\" + SCRATCH_PATH, Operation.ALL))\n",
    "\n",
    "    #local_local_storage_dir = Directory(Directory.LOCAL_STORAGE, path=\"/tmp/pegasus/local\")\\\n",
    "    #                            .add_file_servers(FileServer(\"file:///tmp/pegasus/local\", Operation.ALL))\n",
    "    local_shared_binary_dir = Directory(Directory.LOCAL_STORAGE, path=BINARY_PATH)\\\n",
    "        .add_file_servers(FileServer(\"file://\" + BINARY_PATH, Operation.ALL))\n",
    "    local_shared_binary_dir = Directory(Directory.LOCAL_STORAGE, path=MOCKTAGE_PATH)\\\n",
    "        .add_file_servers(FileServer(\"file://\" + MOCKTAGE_PATH, Operation.ALL))\n",
    "\n",
    "    local.add_directories(local_shared_scratch_dir, local_shared_binary_dir)\n",
    "\n",
    "    \n",
    "    # -----------------------------------------------\n",
    "    # create a \"condorpool\" site\n",
    "    condorpool = Site(\"condorpool\")\\\n",
    "                    .add_pegasus_profile(style=\"condor\")\\\n",
    "                    .add_pegasus_profile(auxillary_local=\"true\")\\\n",
    "                    .add_condor_profile(universe=\"local\")\n",
    "\n",
    "    # create and add a shared scratch directory to the site \"condorpool\"\n",
    "    condorpool_shared_scratch_dir = Directory(Directory.SHARED_SCRATCH, path=SCRATCH_PATH)\\\n",
    "        .add_file_servers(FileServer(\"file://\" + SCRATCH_PATH, Operation.ALL))\n",
    "#     condorpool_local_storage_dir = Directory(Directory.LOCAL_STORAGE, path=SCRATCH_PATH)\\\n",
    "#         .add_file_servers(FileServer(\"file://\" + SCRATCH_PATH, Operation.ALL))\n",
    "    condorpool_shared_binary_dir = Directory(Directory.LOCAL_STORAGE, path=BINARY_PATH)\\\n",
    "        .add_file_servers(FileServer(\"file://\" + BINARY_PATH, Operation.ALL))\n",
    "    condorpool_shared_binary_dir = Directory(Directory.LOCAL_STORAGE, path=MOCKTAGE_PATH)\\\n",
    "        .add_file_servers(FileServer(\"file://\" + MOCKTAGE_PATH, Operation.ALL))\n",
    "    \n",
    "    condorpool.add_directories(condorpool_shared_scratch_dir, condorpool_shared_binary_dir)\n",
    "\n",
    "    # -----------------------------------------------                \n",
    "    # add the sites to the site catalog object\n",
    "    sc.add_sites(local, condorpool)\n",
    "\n",
    "    # write the site catalog to the default path \"./sites.yml\"\n",
    "    #set_trace()\n",
    "    sc.write()\n",
    "    \n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dbeca20-5afc-49c7-8478-0a879c840985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_properties():\n",
    "    props = Properties() \n",
    "    #props[\"pegasus.mode\"] = \"development\"\n",
    "    #props[\"pegasus.data.configuration\"] = \"sharedfs\"\n",
    "    #props[\"pegasus.code.generator\"] = \"Shell\"\n",
    "    props.write()\n",
    "    return props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b51d9735-35c5-40ff-847d-c1f5c2d9be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_watcher(job):\n",
    "    return ('cdo_watcher' in job.metadata)\n",
    "\n",
    "def is_cache(job):\n",
    "    return False\n",
    "    return ('cdo_cache' in job.metadata)\n",
    "\n",
    "def node_memory(job):\n",
    "    if 'maestro_mem' in job.metadata:\n",
    "        return int(float(job.metadata['maestro_mem']))\n",
    "    return None\n",
    "\n",
    "def node_cores(job):\n",
    "    if 'maestro_cores' in job.metadata:\n",
    "        return int(float(job.metadata['maestro_cores']))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3069c30b-6adb-47e7-a4a0-838fbe3f930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_LEVEL = \"0\"\n",
    "GB = 1024 * 1024 * 1024\n",
    "        \n",
    "global_component_id = 0\n",
    "global_offset = 0\n",
    "\n",
    "def current_milli_time():\n",
    "    return round(time.time() * 1000)\n",
    "\n",
    "def start_id_offset(enable_time):\n",
    "    global global_offset\n",
    "    if enable_time:\n",
    "        now = current_milli_time()\n",
    "        now = now % 100000\n",
    "        return now\n",
    "    else:\n",
    "        temp = global_offset\n",
    "        global_offset += 100\n",
    "    return global_offset\n",
    "        \n",
    "def next_id_string(): \n",
    "    global global_component_id\n",
    "    temp = global_component_id\n",
    "    global_component_id += 1\n",
    "    return 'ID-' + str(temp)\n",
    "\n",
    "def cdo_name(file):\n",
    "    return file # 'CDO-' + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74d17932-7139-4236-8cf5-ebf3ebbc3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDO:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename    = filename\n",
    "        #self.cached_name = 'cdo-cache-' + filename\n",
    "        self.input_count = 0\n",
    "        #self.cache       = None\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Define a subclass of the pegasus workflow object \n",
    "#\n",
    "# Override pegasus job insertion, to customize for CDOs\n",
    "#\n",
    "class Maestro_Workflow(Workflow):\n",
    "    \n",
    "    def __init__(self, cdo_dependency, name: str, pool_manager=True, dynamic_provisioning=False, infer_dependencies: bool = True):\n",
    "        print(\"This is the init function\")\n",
    "        super().__init__(name, infer_dependencies)\n",
    "        self.parent_tasks         = {}\n",
    "        self.cdo_dependency       = cdo_dependency\n",
    "        self.pool_manager_startup = pool_manager\n",
    "        self.dynpro_startup       = dynamic_provisioning\n",
    "        \n",
    "        if self.pool_manager_startup:\n",
    "            pool_manager = Job(\"start-pool-manager.sh\", node_label=\"start\\npool\\nmanager\")\\\n",
    "                            .add_args(SCRATCH_PATH, \"pool_manager.stop\", MOCKTAGE_PATH + \"/pool_manager\", SCRATCH_PATH + \"/pminfo\") \\\n",
    "                            .add_metadata(maestro_mem=2*GB, \n",
    "                                          maestro_cores=4,\n",
    "                                          maestro_workflow_core_backend=\"beegfs\", \n",
    "                                          maestro_poolmanager='true')\n",
    "            super().add_jobs(pool_manager)\n",
    "        else:\n",
    "            print('WARNING: pool manager startup was turned off')\n",
    "        \n",
    "        if self.dynpro_startup:\n",
    "            dynpro = Job(\"start-dynpro.sh\", node_label=\"start\\ndynamic\\nprovisioning\")\\\n",
    "                            .add_metadata(maestro_mem=1*GB, \n",
    "                                          maestro_cores=1,\n",
    "                                          maestro_workflow_core_backend=\"beegfs\", \n",
    "                                          maestro_dynpro='true')\n",
    "            super().add_jobs(dynpro)\n",
    "        else:\n",
    "            print('WARNING: pool manager startup was turned off')\n",
    "        \n",
    "    # find the input to a job that generates the named output\n",
    "    def find_parent_dependency(self, output):\n",
    "        for id, job in self.jobs.items():\n",
    "            # if this output matches the request, find the first input\n",
    "            for op in job.get_outputs():\n",
    "                #print('testing', op.lfn, 'against',output)\n",
    "                if op.lfn == output and len(job.get_inputs())>0:\n",
    "                    # just get the filename of the first input\n",
    "                    temp = next(iter(job.get_inputs())).lfn\n",
    "                    #print('Found a match using', temp)                    \n",
    "                    return next(iter(job.get_inputs())).lfn\n",
    "        print('No parent for', output)\n",
    "        return output\n",
    "\n",
    "    def compute_memory_use(self):\n",
    "        # Before we transform the graph and convert files to CDOs, we will tag\n",
    "        # all jons with the amount of memory they 'should' need, based on their\n",
    "        # input files sizes and output file sizes\n",
    "        for id, job in self.jobs.items():\n",
    "            mem = 0\n",
    "            for ip in job.get_inputs():\n",
    "                mem = mem + node_memory(ip)\n",
    "            for op in job.get_outputs():\n",
    "                mem = mem + node_memory(op)\n",
    "            oldmem = node_memory(job)\n",
    "            if oldmem is not None and oldmem!=mem and mem>0:\n",
    "                print(\"Job memory mismatch : oldmem\", oldmem, \"new\", mem)\n",
    "            job.add_metadata(maestro_mem=int(mem*1.5))            \n",
    "        \n",
    "    #\n",
    "    # This is the main routine that walks the graph and converts files to CDOs\n",
    "    # inserts watchers and cache objects.\n",
    "    #\n",
    "    def insert_cdo_jobs(self):        \n",
    "        # note that we must rename input and outputs using new file objects\n",
    "        # to work around shared files that are both input and outputs\n",
    "        # and are replaced by CDO objects\n",
    "        i_replacements = {}\n",
    "        o_replacements = {}\n",
    "        \n",
    "        # store watchers created to prevent creating 2 watchers for the same CDO\n",
    "        # if it is consumed by more than one process\n",
    "        watchers   = {}\n",
    "        cdo_objs   = {}\n",
    "        extra_jobs = []\n",
    "        for id, job in self.jobs.items():                \n",
    "            # For each input :      in -> P -> out\n",
    "            #   replace with parent(in) -> watcher ->\n",
    "            #                                   -> (in)' -> P -> out\n",
    "            if len(job.get_inputs())>0:\n",
    "                for ip in job.get_inputs():\n",
    "                    cdo_enabled = True\n",
    "                    if \"cdo_disabled\" in ip.metadata:\n",
    "                        cdo_enabled = not ip.metadata['cdo_disabled'].lower() in ['true', '1', 't', 'y', 'yes']                    \n",
    "                        #print(ip, \"is cdo enabled\", cdo_enabled)\n",
    "                    if not cdo_enabled:\n",
    "                        print('No substitution for non CDO enabled input', ip.lfn)\n",
    "                        continue\n",
    "                    \n",
    "                    ip_name        = ip.lfn\n",
    "                    trigger_name   = 'T-' + ip_name\n",
    "                    node_label     = '' + ip_name\n",
    "                    \n",
    "                    # track how many consumers are taking this CDO as an input\n",
    "                    if not ip_name in cdo_objs:\n",
    "                        \n",
    "                        cdo_objs[ip_name] = CDO(ip.lfn)\n",
    "                        cdo_objs[ip_name].input_count = 1\n",
    "                        \n",
    "                        # if multiple processes consume the same CDO, we only need one watcher\n",
    "                        # create a watcher for this CDO input\n",
    "                        id_string = next_id_string()\n",
    "                        watcher = Job(\"process-CDO\", _id=id_string, node_label = id_string)\n",
    "                        pseudo_parent = self.find_parent_dependency(ip_name)\n",
    "                        watcher.add_env(MSTRO_LOG_LEVEL=LOG_LEVEL)\n",
    "                        watcher.add_inputs(pseudo_parent)\n",
    "                        watcher.add_outputs(File(trigger_name).add_metadata(dummy_file='true'), stage_out=True)\n",
    "                        watcher.add_args('-l', SCRATCH_PATH,     # log directory \n",
    "                                         '-p', 'pminfo',         # pool manager info\n",
    "                                         '-w',                   # watcher mode\n",
    "                                         '-t', trigger_name,     # trigger_file for pegasus\n",
    "                                         '-c', id_string,        # component name, must be unique\n",
    "                                         '-i', ip_name)          # list of input CDOs to consume\n",
    "                        watcher.add_metadata(cdo_watcher='true', maestro_mem=1*GB, maestro_cores=5)\n",
    "                        watchers[node_label] = watcher\n",
    "                                               \n",
    "                        # Add these new jobs to the actual DAG\n",
    "                        extra_jobs.append(watcher)\n",
    "                        \n",
    "                    else:\n",
    "                        cdo_objs[ip_name].input_count += 1\n",
    "                        #print('Count for', ip_name, cdo_objs[ip_name].input_count) \n",
    "                        \n",
    "                    # any process that outputs this data will need to rename it to the new input name\n",
    "                    o_replacements[ip_name] = ip_name\n",
    "                    \n",
    "                    # for dependencies that use files as input : rename it to the new trigger file name \n",
    "                    i_replacements[ip_name] = trigger_name\n",
    "                \n",
    "            if \"final_job\" in job.metadata:\n",
    "                if self.pool_manager_startup:\n",
    "                    # print ('final job', id, 'corresponds to', job.node_label)\n",
    "                    stop_pm = Job(\"stop-pool-manager.sh\", node_label=\"stop\\npool\\nmanager\")\n",
    "                    stop_pm.add_args(SCRATCH_PATH, 'pool_manager.stop') \\\n",
    "                        .add_metadata(maestro_poolmanager='true', \n",
    "                                      maestro_mem=0.5*GB, \n",
    "                                      maestro_cores=4)\n",
    "                    for op in job.get_outputs():\n",
    "                        stop_pm.add_inputs(op.lfn)\n",
    "                    extra_jobs.append(stop_pm)\n",
    "                    \n",
    "        for job in extra_jobs:\n",
    "            if job._id is None:\n",
    "                job._id = self._get_next_job_id()\n",
    "            self.jobs[job._id] = job\n",
    "            job.node_label = job._id\n",
    "        \n",
    "        # when we replace an input to a job with a CDO version of it, we have to create a new \"File\" object\n",
    "        # because if we simply change the path/name, we might modify the same 'file' object on different \n",
    "        # jobs and we can get links between tasks we were not expecting\n",
    "        for id, job in self.jobs.items():\n",
    "            # for each output, specify consumer count for each\n",
    "            output_counts = []\n",
    "            for op in job.get_outputs():\n",
    "                if (op is not None) and op.lfn in cdo_objs:\n",
    "                    output_counts += [cdo_objs[op.lfn].input_count]\n",
    "                    job.add_args('-O', *output_counts)\n",
    "                    #print('Set O for', op.lfn, cdo_objs[op.lfn].input_count) \n",
    "                    \n",
    "            for u in job.uses:\n",
    "                if u.file.lfn in i_replacements:\n",
    "                    # Replace an input that we have changed to point to the dummy file\n",
    "                    if u._type == \"input\":\n",
    "                        u.file = File(i_replacements[u.file.lfn]).add_metadata(dummy_file='true')\n",
    "                    # Replace an output that we have changed to point to the CDO\n",
    "                    if u._type == \"output\":\n",
    "                        # we add a watcher and a cache as dependencies of this CDO, but watcher is not counted\n",
    "                        # output_counts += ['1'] \n",
    "                        # make sure the CDO cache is kept alive for N real consumers\n",
    "                        # cdo_objs[u.file.lfn].cache.add_args('-O', cdo_objs[u.file.lfn].input_count)\n",
    "                        # cdo_objs[u.file.lfn].cache.add_metadata(maestro_cores=2)                        \n",
    "\n",
    "                        if u.file.lfn in cdo_objs:\n",
    "                            if self.cdo_dependency :\n",
    "                                u.file = File(o_replacements[u.file.lfn]).add_metadata(cdo_data='true') \n",
    "                            else:\n",
    "                                u.file = None\n",
    "                                \n",
    "                \n",
    "            # otherwise, assume 2 consumers (watcher + cache)\n",
    "            # elif not is_cache(job) and not is_watcher(job):                    \n",
    "            #     if job.transformation=='process-CDO':\n",
    "            #         job.add_args('-O', '1')\n",
    "            #     else:\n",
    "            #         ...\n",
    "                    #print(job)\n",
    "\n",
    "            job.uses = [x for x in job.uses if x.file is not None]\n",
    "                                    \n",
    "        print('Substitution of command line filenames for cached CDOs')\n",
    "        for id, job in self.jobs.items():                \n",
    "            # watchers always watch for the original CDO (no name change)\n",
    "            # cache's will output a CDO with a new name (name change handled by cache itself)\n",
    "            # other objects must rename their inbput file/cdo names to the renamed version\n",
    "            if is_watcher(job) or is_cache(job):\n",
    "                ...\n",
    "            else:\n",
    "                new_args = []\n",
    "                # we must only change input CDO names, as original output names go into the cache \n",
    "                input = False\n",
    "                for a in job.args:\n",
    "                    if a == '-i':\n",
    "                        input = True\n",
    "                    if a == '-o':\n",
    "                        input = False\n",
    "                    if input and isinstance(a, File):\n",
    "                        cdo_name = a.lfn # 'cdo-cache-' + a.lfn\n",
    "                        a = File(cdo_name)\n",
    "                    new_args.append(a)\n",
    "                job.args = new_args\n",
    "            #\n",
    "            # print(job.args)\n",
    "                    \n",
    "        for d, val in self.dependencies.items():\n",
    "            print('Dependency', d, val)\n",
    "            \n",
    "    def insert_shutdown_jobs(self):\n",
    "        if self.dynpro_startup:\n",
    "            for id, job in self.jobs.items():                \n",
    "                if \"final_job\" in job.metadata:\n",
    "                    dynpro = Job(\"start-dynpro.sh\", node_label=\"stop\\ndynamic\\nprovisioning\")\n",
    "                    dynpro.add_args(SCRATCH_PATH, 'dynpro.stop') \\\n",
    "                        .add_metadata(maestro_dynpro='true', \n",
    "                                      maestro_mem=0.5*GB, \n",
    "                                      maestro_cores=1)\n",
    "                    for op in job.get_outputs():\n",
    "                        dynpro.add_inputs(op.lfn)\n",
    "            super().add_jobs(dynpro)\n",
    "                    \n",
    "        \n",
    "    def execute_using_slurm(self):\n",
    "        return        \n",
    "    \n",
    "    def build_dependencies(self):\n",
    "        # buiod list of children for each task\n",
    "        self.infer_dependencies = True\n",
    "        self._infer_dependencies()\n",
    "        \n",
    "        # construct list of parents from child list\n",
    "        for k,v in self.dependencies.items():\n",
    "            for c in v.children_ids:\n",
    "                if c in self.parent_tasks:\n",
    "                    self.parent_tasks[c] = self.parent_tasks[c] + [k]\n",
    "                else:\n",
    "                    self.parent_tasks[c] = [k]\n",
    "                    \n",
    "        for task, parent in self.parent_tasks.items():\n",
    "            #print('Task', task, 'Depends on', parent)\n",
    "            ...\n",
    "        return\n",
    "        \n",
    "    def execute_using_splinter(self, srun):\n",
    "        # get the transformation catalog\n",
    "        #print(dir(self.transformation_catalog))\n",
    "        tc = self.transformation_catalog.transformations        \n",
    "        # for x in tc:\n",
    "        #     print (x)\n",
    "            \n",
    "        # build parent/child dependency lists \n",
    "        self.build_dependencies()\n",
    "        # create a splinter workflow\n",
    "        swf = splinter.splinter_workflow()\n",
    "        \n",
    "        for id, job in self.jobs.items():\n",
    "            t_string = \"None::\" + job.transformation + \"::None\"\n",
    "            t_path = tc[t_string].sites['local'].pfn            \n",
    "            # convert any file objects to string pathnames in arg list\n",
    "            command = [t_path] + [str(a) for a in job.args]\n",
    "            parents = self.parent_tasks[id] if id in self.parent_tasks else []\n",
    "            try:\n",
    "                memory = node_memory(job)\n",
    "                cores  = node_cores(job)\n",
    "            except:\n",
    "                print('Invalid JOB', job, job.args)\n",
    "                memory = None\n",
    "                cores  = None\n",
    "            if memory is None:\n",
    "                print('Invalid memory', job, job.args)\n",
    "            if cores is None:\n",
    "                print('Invalid cores', job, job.args)\n",
    "            splinter_task = splinter.task(id, command, parents, cores, memory)\n",
    "            swf.add_task(splinter_task)\n",
    "            \n",
    "        # poll freq, use srun\n",
    "        swf.execute_workflow(0.1, srun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28d9d627-cbe0-4fa9-a824-1960de781284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def regex_increment_first(instring, N):\n",
    "    # preceeded by \"-\" : followed by \"-\"\n",
    "    out = instring\n",
    "    for i in range(0,N):\n",
    "        out = re.sub('(?<=-)(\\d+)(?=-)', lambda x: str(int(x.group(0)) + 1).zfill(2), out)\n",
    "    return out\n",
    "\n",
    "def regex_increment_last(instring, N):\n",
    "    # preceeded by \"-\" : followed by EOL\n",
    "    out = instring\n",
    "    for i in range(0,N):\n",
    "        out = re.sub('(?<=-)(\\d+$)', lambda x: str(int(x.group(0)) + 1).zfill(2), out)\n",
    "    return out\n",
    "\n",
    "# x = \"f-04-05\"\n",
    "# print(regex_increment_first(x,2))\n",
    "# print(regex_increment_last(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "256687fa-37f6-4e88-8e06-defd7c726139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(p):\n",
    "    return (random.randint(1,100) <= p)\n",
    "\n",
    "# x0 = 0;\n",
    "# x1 = 0;\n",
    "# x2 = 0;\n",
    "# for a in range(0,10000):\n",
    "#     if probability(0):\n",
    "#         x0 += 1\n",
    "#     if probability(50):\n",
    "#         x1 += 1\n",
    "#     if probability(100):\n",
    "#         x2 += 1\n",
    "        \n",
    "# print(x0, x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64da5f10-aea4-493f-88e0-14fb4f839ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demo_workflow(wf, rc, maestro=False, data_size=65536, id_offset=0, iterations=2, forks=2, subforks=2):\n",
    "\n",
    "    random.seed(a=123456)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # Create a single input file that will start our graph\n",
    "    fa = File(\"root-data.txt\").add_metadata(creator=\"biddisco\", \n",
    "                                            cdo_disabled=\"true\", \n",
    "                                            maestro_enabled=\"false\", \n",
    "                                            node_label='root',\n",
    "                                            maestro_mem = data_size)\n",
    "    rc.add_replica(\n",
    "       site=\"local\", lfn=fa, pfn=Path(DATA_PATH).resolve() / \"root-data.txt\"\n",
    "    )\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # Create a single job that will fork into N new files\n",
    "    # Names are xxx-FORK-ITERATION\n",
    "    files = []    \n",
    "    for f in range(0,forks): # originally N forks\n",
    "        # create string \"f-0N-00\"\n",
    "        files.append(File(\"f-\" + f\"{f:0>2}\" + \"-00\").add_metadata(maestro_mem = data_size))\n",
    "    \n",
    "    arg_defaults = ['-l', SCRATCH_PATH,   # log directory \n",
    "                    '-p', 'pminfo',       # pool manager info\n",
    "                    '-d', int(data_size)] # default cdo/file size\n",
    "    \n",
    "    if not maestro:\n",
    "        arg_defaults += ['-b', BEEGFS_PATH]\n",
    "        arg_defaults += ['-F'] # filemode - no CDOs to be generated in this mode, just HDF5 files\n",
    "        \n",
    "    id_string = next_id_string()\n",
    "    node_label = \"preprocess\"\n",
    "    \n",
    "    job_preprocess = Job(\"process-CDO\", _id=id_string, node_label=node_label) \\\n",
    "                            .add_env(MSTRO_LOG_LEVEL=LOG_LEVEL)       \\\n",
    "                            .add_inputs(fa)                           \\\n",
    "                            .add_outputs(*files, stage_out=True)      \\\n",
    "                            .add_metadata(node_colour='#e959d9', maestro_cores=4) \\\n",
    "                            .add_args(*arg_defaults,\n",
    "                                      '-c', id_string,              # component name, must be unique\n",
    "                                      '-o', *[x for x in files])    # list of output CDOs to produce\n",
    "    # print('args are', job_preprocess.args) \n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # for each fork, produce a chain of iterations file_in->P->file_out processes\n",
    "    job_iter = []\n",
    "    for i in range(0, iterations):\n",
    "        out_files = []\n",
    "        for f in range(0,forks):\n",
    "            \n",
    "            if f<len(files):\n",
    "                in_file = files[f]\n",
    "                out_name = regex_increment_last(in_file.lfn, 1)\n",
    "            else:\n",
    "                in_file = files[f % len(files)]\n",
    "                out_name = regex_increment_last(in_file.lfn, i+1)\n",
    "                for ff in range(0, 1 + (f % len(files))):\n",
    "                    out_name = regex_increment_first(out_name, f)\n",
    "                \n",
    "            in_name = in_file.lfn\n",
    "            f_out = File(out_name).add_metadata(maestro_mem=node_memory(in_file))\n",
    "            out_files.append(f_out)\n",
    "\n",
    "            id_string = next_id_string()\n",
    "            node_label = str(f)+\"-process-\" + str(i)\n",
    "            job_iter.append(Job(\"process-CDO\", _id=id_string, node_label=node_label)\\\n",
    "                            .add_metadata(node_colour='#ff7fb3', maestro_cores=5)\\\n",
    "                            .add_env(MSTRO_LOG_LEVEL=LOG_LEVEL) \\\n",
    "                            .add_inputs(in_file)               \\\n",
    "                            .add_outputs(f_out, stage_out=True) \\\n",
    "                            .add_args(*arg_defaults,\n",
    "                                      '-c', id_string,              # component name, must be unique\n",
    "                                      '-i', in_file,               # list of input CDOs to produce\n",
    "                                      '-o', f_out))                 # output (default 1 consumer omitted)                \n",
    "                                \n",
    "        #print('Files',i, files, out_files) \n",
    "        files = out_files\n",
    "            \n",
    "            # on first iteration, add an extra fork+join to test our CDO stuff\n",
    "#             if False and i==0 and subforks>1:\n",
    "#                 subfiles = []\n",
    "#                 # create a set of tasks that fork from a single input\n",
    "#                 for sf in range(0,subforks):\n",
    "                    \n",
    "#                     #if random.randint(1,5)==1:                        \n",
    "#                     #    sf_out.add_metadata(cdo_disabled=\"true\")\n",
    "                    \n",
    "#                     sf_out = File(out_name + \"-\" + str(sf)).add_metadata(maestro_mem=node_memory(in_file))            \n",
    "#                     subfiles.append(sf_out)\n",
    "#                     id_string = next_id_string()\n",
    "#                     node_label = sf_out.lfn\n",
    "#                     forkjob = Job(\"process-CDO\", _id=id_string, node_label=id_string)\\\n",
    "#                                 .add_metadata(node_colour='#1b9e77', maestro_cores=2) \\\n",
    "#                                 .add_env(MSTRO_LOG_LEVEL=LOG_LEVEL)  \\\n",
    "#                                 .add_inputs(in_file)                \\\n",
    "#                                 .add_outputs(sf_out, stage_out=True) \\\n",
    "#                                 .add_args(*arg_defaults,\n",
    "#                                           '-c', id_string,        # component name, must be unique\n",
    "#                                           '-i', in_file,         # (list of) input CDO(s) to consume\n",
    "#                                           '-o', sf_out)           # output (default 1 consumer omitted)\n",
    "#                     job_iter.append(forkjob)\n",
    "\n",
    "#                 # join all the tasks back into a single output    \n",
    "#                 id_string = next_id_string()\n",
    "#                 node_label = str(f)+\"-process-\" + str(i)\n",
    "#                 joinjob = Job(\"process-CDO\", _id=id_string, node_label=id_string)\\\n",
    "#                                 .add_metadata(node_colour='#3b97be', maestro_cores=2)\\\n",
    "#                                 .add_env(MSTRO_LOG_LEVEL=LOG_LEVEL) \\\n",
    "#                                 .add_inputs(*subfiles)              \\\n",
    "#                                 .add_outputs(f_out, stage_out=True) \\\n",
    "#                                 .add_args(*arg_defaults,\n",
    "#                                           '-c', id_string,              # component name, must be unique\n",
    "#                                           '-i', *[x for x in subfiles], # (list of) input CDO(s) to produce\n",
    "#                                           '-o', f_out)                  # output (default 1 consumer omitted)                \n",
    "#                 job_iter.append(joinjob)\n",
    "                \n",
    "            # else:\n",
    "        \n",
    "\n",
    "    fd = File(\"Output\").add_metadata(final_output=\"true\", \n",
    "                                  cdo_disabled=\"true\", \n",
    "                                  maestro_mem = data_size)\n",
    "    id_string = next_id_string()\n",
    "    node_label = \"analyze\"\n",
    "    job_analyze = Job(\"process-CDO\", _id=id_string, node_label=node_label)                \\\n",
    "                    .add_env(MSTRO_LOG_LEVEL=\"0\")                         \\\n",
    "                    .add_inputs(*files)                                   \\\n",
    "                    .add_outputs(fd, stage_out=True)                      \\\n",
    "                    .add_metadata(final_job='true', node_colour='#8a4f4f', maestro_cores=4)\\\n",
    "                    .add_args(*arg_defaults,\n",
    "                              '-c', id_string,              # component name, must be unique\n",
    "                              '-i', *[x for x in files],    # list of input CDOs to produce\n",
    "                              '-t', fd.lfn)                 # output (default 1 consumer omitted)                \n",
    "\n",
    "    wf.add_jobs(job_preprocess, job_analyze)\n",
    "    for j in job_iter:\n",
    "        wf.add_jobs(j)\n",
    "\n",
    "    if isinstance(wf,Maestro_Workflow):\n",
    "        wf.compute_memory_use()\n",
    "        if maestro:\n",
    "            wf.insert_cdo_jobs()\n",
    "        else:\n",
    "            wf.insert_shutdown_jobs()\n",
    "        \n",
    "    wf.add_replica_catalog(rc)\n",
    "    wf.write(file=wf.name)\n",
    "    print('Written workflow to', wf.name)\n",
    "    return wf.path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b257950-ff74-450e-8210-e3a397dfcdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time/Id offset is 0\n",
      "Written workflow to demo-orig.yml\n",
      "Time/Id offset is 0\n",
      "This is the init function\n",
      "WARNING: pool manager startup was turned off\n",
      "No substitution for non CDO enabled input root-data.txt\n",
      "Substitution of command line filenames for cached CDOs\n",
      "Written workflow to demo-maestro.yml\n",
      "Time/Id offset is 0\n",
      "This is the init function\n",
      "WARNING: pool manager startup was turned off\n",
      "Written workflow to demo-beegfs.yml\n",
      "[NbConvertApp] Converting notebook CDO-workflow-slurm-splinter-workflow.ipynb to script\n",
      "[NbConvertApp] Writing 37630 bytes to CDO-workflow-slurm-splinter-workflow.py\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# cdo_dependencies : false, CDOs are not matched between in/out so CDO consumers do not depend on producers, the DAG is split\n",
    "#                  : true, CDOs behave like files and trigger dependencies\n",
    "# display_files : true, files appear as nodes in the graph, otherwise not\n",
    "# transitive_reduction : true - remove links that are superfluous - transitive, between job-job bypassing files\n",
    "\n",
    "# cdo_dependencies must be False when executing a CDO enabled workflow\n",
    "\n",
    "cdo_dependencies     = False\n",
    "display_files        = True\n",
    "transitive_reduction = True\n",
    "left_right           = True\n",
    "\n",
    "if os.path.isfile(\"pegasus.properties\"):\n",
    "    os.remove(\"pegasus.properties\")\n",
    "if os.path.isfile(\"sites.yml\"):\n",
    "    os.remove(\"sites.yml\")\n",
    "\n",
    "rc1 = ReplicaCatalog()\n",
    "rc2 = ReplicaCatalog()\n",
    "rc3 = ReplicaCatalog()\n",
    "sco = build_site_catalog()    \n",
    "prp = build_properties()\n",
    "\n",
    "# ---------------------------------------\n",
    "# Convert workflow into nice DAG display\n",
    "iterations = 3\n",
    "forks = 5\n",
    "subforks = 0\n",
    "\n",
    "# ---------------------------------------\n",
    "# Generate workflows, one original, one maestro enabled\n",
    "\n",
    "TIME_OFFSETS = True\n",
    "\n",
    "global_component_id = 0\n",
    "print('Time/Id offset is', global_component_id)\n",
    "wfo = Workflow(name=\"demo-orig.yml\")\n",
    "build_transformation_catalog(wfo)\n",
    "file1 = generate_demo_workflow(wfo, rc1, iterations=iterations, forks=forks, subforks=subforks)\n",
    "\n",
    "global_component_id = 0\n",
    "print('Time/Id offset is', global_component_id)\n",
    "wfm = Maestro_Workflow(cdo_dependencies, name=\"demo-maestro.yml\", pool_manager=True, infer_dependencies=False)\n",
    "build_transformation_catalog(wfm)\n",
    "file2 = generate_demo_workflow(wfm, rc2, maestro=True,  iterations=iterations, forks=forks, subforks=subforks, data_size=1*GB)\n",
    "\n",
    "global_component_id = 0\n",
    "print('Time/Id offset is', global_component_id)\n",
    "wff = Maestro_Workflow(cdo_dependencies, name=\"demo-beegfs.yml\", pool_manager=False, dynamic_provisioning=True, infer_dependencies=False)\n",
    "build_transformation_catalog(wff)\n",
    "file3 = generate_demo_workflow(wff, rc3, maestro=False, iterations=iterations, forks=forks, subforks=subforks)\n",
    "\n",
    "save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09058deb-3116-465d-b080-17202d5b9a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args size 1073741824, iterations 5, forks 2\n",
      "This is the init function\n",
      "WARNING: pool manager startup was turned off\n",
      "WARNING: pool manager startup was turned off\n",
      "Written workflow to demo-filemode.yml\n",
      "Got node list ['localhost']\n",
      "Please set env var LSTOPO : using : /usr/bin/lstopo-no-graphics\n",
      "Node data oryx2:0:0:0:0:\n",
      "\n",
      "'localhost' generated an exception: Failed to parse size! (input '' was tokenized as [])\n",
      "Task ID-0 Depends on []\n",
      "Task ID-11 Depends on ['ID-9', 'ID-10']\n",
      "Task ID-1 Depends on ['ID-0']\n",
      "Task ID-2 Depends on ['ID-0']\n",
      "Task ID-3 Depends on ['ID-1']\n",
      "Task ID-4 Depends on ['ID-2']\n",
      "Task ID-5 Depends on ['ID-3']\n",
      "Task ID-6 Depends on ['ID-4']\n",
      "Task ID-7 Depends on ['ID-5']\n",
      "Task ID-8 Depends on ['ID-6']\n",
      "Task ID-9 Depends on ['ID-7']\n",
      "Task ID-10 Depends on ['ID-8']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 2: /usr/bin/lstopo-no-graphics: No such file or directory\n",
      "/bin/bash: line 3: /usr/bin/lstopo-no-graphics: No such file or directory\n",
      "/bin/bash: line 4: /usr/bin/lstopo-no-graphics: No such file or directory\n",
      "/bin/bash: line 5: /usr/bin/lstopo-no-graphics: No such file or directory\n",
      "/bin/bash: line 6: /usr/bin/lstopo-no-graphics: No such file or directory\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_workers must be greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_203499/286903014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mwff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_using_splinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_203499/240385163.py\u001b[0m in \u001b[0;36mexecute_using_splinter\u001b[0;34m(self, srun)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# poll freq, use srun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mswf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_workflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/maestro/pegasus-workflow-development-environment/shared-data/maestro-test/splinter.py\u001b[0m in \u001b[0;36mexecute_workflow\u001b[0;34m(self, poll_frequency, srun)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mlast_now\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mpoll_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_workflow_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/thread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_workers, thread_name_prefix, initializer, initargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mmax_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_workers\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_workers must be greater than 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_workers must be greater than 0"
     ]
    }
   ],
   "source": [
    "if ('daint' in hostname) or ('nid' in hostname):\n",
    "    srun = True\n",
    "else:\n",
    "    srun = False\n",
    "\n",
    "class GetOutOfLoop( Exception ):\n",
    "    pass\n",
    "\n",
    "count = 0\n",
    "\n",
    "PATH1 ='/scratch/snx3000/' + user + '/maestro-scratch/'    \n",
    "PATH2  ='/users/' + user + '/beegfs/'\n",
    "TIME_OFFSETS = False\n",
    "\n",
    "if not is_notebook():\n",
    "    iterlist = [int(sys.argv[1])]\n",
    "    forklist = [int(sys.argv[2])]\n",
    "    sizelist = [int(sys.argv[3])]\n",
    "    cdolist  = [sys.argv[4]]\n",
    "else:\n",
    "    iterlist = [5, 10, 15, 20]\n",
    "    forklist = [2,4,6,8]\n",
    "    sizelist = [1*GB, 2*GB, int(3.99*GB)]\n",
    "    cdolist  = ['lustre'] # ['cdo','beegfs','lustre']\n",
    "\n",
    "# iterlist = [10]\n",
    "# forklist = [2]\n",
    "# sizelist = [1*GB]\n",
    "# cdolist  = ['lustre'] # ['cdo','beegfs','lustre']\n",
    "\n",
    "rc1 = ReplicaCatalog()\n",
    "    \n",
    "try:\n",
    "    for cdo in cdolist:\n",
    "        for forks in forklist:\n",
    "            for iterations in iterlist:\n",
    "                for size in sizelist:\n",
    "                    \n",
    "                    # for fs in [PATH1, PATH2]:\n",
    "                    subforks=0\n",
    "\n",
    "                    print(f'Args size {size}, iterations {iterations}, forks {forks}') \n",
    "                    \n",
    "                    global_component_id = 0\n",
    "                    \n",
    "                    if cdo == 'cdo':\n",
    "                        SCRATCH_PATH =os.getcwd()\n",
    "                        BEEGFS_PATH  =os.getcwd()                        \n",
    "                        wff = Maestro_Workflow(cdo_dependencies, name=\"demo-cdo.yml\", pool_manager=True , dynamic_provisioning=False, infer_dependencies=False)\n",
    "                        build_transformation_catalog(wff)\n",
    "                        file3 = generate_demo_workflow(wff, rc1, maestro=True, iterations=iterations, forks=forks, subforks=subforks, data_size=size)\n",
    "                    elif cdo=='beegfs':                        \n",
    "                        wff = Maestro_Workflow(cdo_dependencies, name=\"demo-beegfs.yml\", pool_manager=False, dynamic_provisioning=False, infer_dependencies=False)\n",
    "                        build_transformation_catalog(wff)\n",
    "                        file3 = generate_demo_workflow(wff, rc1, maestro=False, iterations=iterations, forks=forks, subforks=subforks, data_size=size)\n",
    "                    elif cdo=='lustre':\n",
    "                        SCRATCH_PATH =os.getcwd()\n",
    "                        BEEGFS_PATH  =os.getcwd()                        \n",
    "                        # disabling dynamic provisioning to avoinf start/stopping it many times\n",
    "                        wff = Maestro_Workflow(cdo_dependencies, name=\"demo-filemode.yml\", pool_manager=False, dynamic_provisioning=False, infer_dependencies=False)\n",
    "                        build_transformation_catalog(wff)\n",
    "                        file3 = generate_demo_workflow(wff, rc1, maestro=False, iterations=iterations, forks=forks, subforks=subforks, data_size=size)\n",
    "                    else:\n",
    "                        print(\"Error, wrong cdo/beegfs/lustre param\")\n",
    "                        \n",
    "                    start = time.time()\n",
    "                    wff.execute_using_splinter(srun)\n",
    "                    end = time.time()\n",
    "                    elapsed = end-start\n",
    "                                            \n",
    "                    print(f'CSVData, Args_size, {size}, iterations, {iterations}, forks, {forks}, IO, {cdo}, Elapsed, {elapsed}')\n",
    "                    # stime = time.strftime(\"%Y-%m-%d.%H:%M:%S\", time.gmtime())\n",
    "                    # os.rename('commands.txt', 'commands-' + stime + '.txt')\n",
    "\n",
    "                    count += 1\n",
    "                    # if count>=1:\n",
    "                    #     raise GetOutOfLoop\n",
    "except GetOutOfLoop:\n",
    "    pass\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363020c-ae67-4dc3-af1f-77bd98113347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#srun = True\n",
    "#wfm.execute_using_splinter(srun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e2493-5457-44bd-b664-1574ea05c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wfo.plan(submit=True, sites=['condorpool'], cleanup=False)\\\n",
    "# wfm.plan(submit=True, cleanup=False, sites=[\"condorpool\"],verbose=0)\\\n",
    "#     .wait()\\\n",
    "#     .analyze()\\\n",
    "#     .statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e61cb-3aea-4c30-8c00-d5f8d1fb2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wfm.halt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peg-env",
   "language": "python",
   "name": "peg-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
